{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2774d8-77d9-4b92-9b39-b7e945eb8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 11-16 04:17:02 [__init__.py:241] Automatically detected platform cuda.\n",
      "GPU count: 2\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "from transformers import AutoTokenizer, GemmaTokenizerFast\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from jiwer import cer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "ROOT_DIR = \"/project/lt200304-dipmt/paweekorn\"\n",
    "MODEL_PATH = f\"{ROOT_DIR}/models/base/gemma3-4b-it\"\n",
    "ADAPTER_PATH = None\n",
    "# ADAPTER_PATH = f\"{ROOT_DIR}/models/adapter/gemma3-4b-it/checkpoint-1242\"\n",
    "\n",
    "print(\"GPU count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d554f4-4af8-4619-aad1-dbf3c50952b5",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b662c0e-8098-4de4-9545-5772df1a497c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2785, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ENG</th>\n",
       "      <th>THA</th>\n",
       "      <th>WIPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Educational services, namely, conducting semin...</td>\n",
       "      <td>‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>training of drivers, road service employees, o...</td>\n",
       "      <td>‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>providing online publications in the nature of...</td>\n",
       "      <td>‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ‡∏õ‡∏£‡∏∞...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>information with respect to leisure activities...</td>\n",
       "      <td>‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>planning, arranging and operating of movies, s...</td>\n",
       "      <td>‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞‡∏Ñ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME                                                ENG  \\\n",
       "0    41  Educational services, namely, conducting semin...   \n",
       "1    41  training of drivers, road service employees, o...   \n",
       "2    41  providing online publications in the nature of...   \n",
       "3    41  information with respect to leisure activities...   \n",
       "4    41  planning, arranging and operating of movies, s...   \n",
       "\n",
       "                                                 THA  \\\n",
       "0  ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ...   \n",
       "1  ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ...   \n",
       "2  ‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ‡∏õ‡∏£‡∏∞...   \n",
       "3  ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å...   \n",
       "4  ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞‡∏Ñ...   \n",
       "\n",
       "                                                WIPO  \n",
       "0  Education; providing of training; entertainmen...  \n",
       "1  Education; providing of training; entertainmen...  \n",
       "2  Education; providing of training; entertainmen...  \n",
       "3  Education; providing of training; entertainmen...  \n",
       "4  Education; providing of training; entertainmen...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/project/lt200304-dipmt/paweekorn/data/DS01/test_v1.csv')\n",
    "with open('/project/lt200304-dipmt/paweekorn/data/wipo/WIPO.json', 'r') as f:\n",
    "    wipo_data = json.load(f)\n",
    "\n",
    "wipo_data = {int(k): v for k, v in wipo_data.items()}\n",
    "test_df['WIPO'] = test_df['NAME'].map(wipo_data)\n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ba4c4-bf6f-4fb2-b549-543fd1b6a36e",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b9bcf5-a26b-4742-9eba-261637ed6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(ROOT_DIR, \"script\"))  # parent dir\n",
    "from utils.retrieval import process_query\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)\n",
    "with open(f\"{ROOT_DIR}/data/prompt/base_en2th.txt\", \"r\") as f:\n",
    "    instruction = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c031b6c-28a5-4c8b-af49-cb5d988f0c98",
   "metadata": {},
   "source": [
    "**RAG setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a185c37f-0e2d-467e-9f3d-403144b0df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=f\"{ROOT_DIR}/models/retriever/{retriever}\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    f\"{ROOT_DIR}/vector/{retriever}\", \n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "gpu_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, vectorstore.index)\n",
    "vectorstore.index = gpu_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c10c5-56a3-408a-b947-c8997785888b",
   "metadata": {},
   "source": [
    "**Full Text Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb27a874-1a48-4dd4-8bae-d918be72c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = pd.read_csv(f\"{ROOT_DIR}/data/unique_no_test.csv\")\n",
    "\n",
    "# in-memory save\n",
    "db = sqlite3.connect(':memory:')\n",
    "cur = db.cursor()\n",
    "cur.execute('create virtual table wipo_table using fts5(eng, tha, tokenize=\"unicode61\");')\n",
    "\n",
    "# bulk index records\n",
    "cur.executemany('insert into wipo_table (eng, tha) values (?,?);', unique_df[['ENG', 'THA']].to_records(index=False))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf789a-7134-4ce1-8fe1-0822771fe0f0",
   "metadata": {},
   "source": [
    "#### combine in prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7420306-3259-483c-83eb-993841ddcd76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2785/2785 [00:15<00:00, 178.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "## Instructions:\n",
      "You are an expert in the classification of goods and services under the WIPO Nice Classification system. Your task is to translate product names from English to accurate and direct Thai.\n",
      "\n",
      "**Translation Guidelines:**\n",
      "- Maintain the punctuation alignment of the input text.\n",
      "- Use Thai legal and commercial terminology appropriate for trademarks and product classification.\n",
      "- Do not include explanations, commentary, or any information beyond the translation output.\n",
      "- Provided output in the format of {\"thai_translation\": \"Thai translation\"}\n",
      "\n",
      "**Product Domain:**\n",
      "Education; providing of training; entertainment; sporting and cultural activities.\n",
      "\n",
      "## Retrieved References:\n",
      "\n",
      "English: Educational service, namely, conducting seminar, conference, workshop, online tutorial and computer application training in the field of computer software, business analytics and business intelligence and distributing course material in connection therewith\n",
      "Thai: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà, ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤, ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥, ‡∏™‡∏≠‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à, ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏™‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≠‡∏ô‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n",
      "\n",
      "English: Educational service, namely, developing, arranging, and conducting educational conference and program and providing course of instruction and workshop in the field of computer, computer software, computer peripheral, computer networking, technology planning, business management and distribution of course and educational material in connection therewith\n",
      "Thai: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ï‡πà‡∏≠‡∏û‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß\n",
      "\n",
      "English: computer service, namely, designing, developing, and maintaining computer software application for others and consulting service related thereto\n",
      "Thai: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà, ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö, ‡∏û‡∏±‡∏í‡∏ô‡∏≤, ‡πÅ‡∏•‡∏∞‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÅ‡∏≠‡∏û‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡πà‡∏ô‡∏ã‡∏≠‡∏ü‡∏ó‡πå‡πÅ‡∏ß‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏≠‡∏∑‡πà‡∏ô, ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n",
      "\n",
      "**Note:** If the retrieved references contain identical English terms with different Thai translations (ambiguity), you must use your expert judgment to select the most appropriate and contextually accurate translation for the current input.\n",
      "\n",
      "## Input:\n",
      "Educational services, namely, conducting seminars, conferences, workshops, online tutorials and computer application training in the fields of computer software, business analytics and business intelligence and distributing course materials in connection therewith\n",
      "\n",
      "\n",
      "## Output:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def formatting_prompt(df):\n",
    "    batch = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        prompt = instruction.format(\n",
    "            WIPO=row['WIPO'],\n",
    "            # RAG_DOC=\"\",\n",
    "            RAG_DOC=process_query(embeddings=embeddings, vectorstore=vectorstore, \n",
    "                                  db_cur=cur, query=row['ENG'], how=\"rag\"),\n",
    "            ENGLISH=row[\"ENG\"]\n",
    "        )\n",
    "        chat = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "        batch.append(chat)\n",
    "    return batch\n",
    "\n",
    "test_set = formatting_prompt(test_df)\n",
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f0e07-8378-43fd-bcd8-f4825bc07919",
   "metadata": {},
   "source": [
    "## Inference Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dd0c7d-781d-4667-bb65-e291d7c3e8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-16 04:17:41 [utils.py:326] non-default args: {'model': '/project/lt200304-dipmt/paweekorn/models/base/gemma3-4b-it', 'max_model_len': 4096, 'enable_prefix_caching': True, 'gpu_memory_utilization': 0.5, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enforce_eager': True, 'max_lora_rank': 64}\n",
      "INFO 11-16 04:17:50 [__init__.py:711] Resolved architecture: Gemma3ForConditionalGeneration\n",
      "INFO 11-16 04:17:50 [__init__.py:1750] Using max model len 4096\n",
      "WARNING 11-16 04:17:50 [__init__.py:1171] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 11-16 04:17:53 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 11-16 04:17:53 [__init__.py:3565] Cudagraph is disabled under eager mode\n",
      "WARNING 11-16 04:17:56 [__init__.py:2921] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "INFO 11-16 04:18:02 [__init__.py:241] Automatically detected platform cuda.\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:05 [core.py:636] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:05 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='/project/lt200304-dipmt/paweekorn/models/base/gemma3-4b-it', speculative_config=None, tokenizer='/project/lt200304-dipmt/paweekorn/models/base/gemma3-4b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/project/lt200304-dipmt/paweekorn/models/base/gemma3-4b-it, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":0,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":0,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:06 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m WARNING 11-16 04:18:07 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:12 [gpu_model_runner.py:1953] Starting to load model /project/lt200304-dipmt/paweekorn/models/base/gemma3-4b-it...\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:12 [gpu_model_runner.py:1985] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:13 [cuda.py:345] Using FlexAttention backend for head_size=72 on V1 engine.\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:13 [__init__.py:3565] Cudagraph is disabled under eager mode\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:13 [cuda.py:328] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:13 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.80s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.86s/it]\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:21 [gpu_model_runner.py:2007] Model loading took 3.7575 GiB and 8.297242 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:21 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 8192 tokens, and profiled with 31 image items of the maximum feature size.\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:50 [gpu_worker.py:276] Available KV cache memory: 12.66 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m WARNING 11-16 04:18:50 [kv_cache_utils.py:971] Add 1 padding layers, may waste at most 3.45% KV cache memory\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:50 [kv_cache_utils.py:1013] GPU KV cache size: 94,800 tokens\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:50 [kv_cache_utils.py:1017] Maximum concurrency for 4,096 tokens per request: 23.07x\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:51 [core.py:214] init engine (profile, create kv cache, warmup model) took 29.90 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m INFO 11-16 04:18:52 [__init__.py:3565] Cudagraph is disabled under eager mode\n",
      "INFO 11-16 04:18:52 [llm.py:298] Supported_tasks: ['generate']\n",
      "ERROR 11-16 04:23:52 [core_client.py:562] Engine core proc EngineCore_0 died unexpectedly, shutting down client.\n"
     ]
    }
   ],
   "source": [
    "if not bool(ADAPTER_PATH) or \"fine-tuned\" in MODEL_PATH:\n",
    "    enable_lora = False ; lora_req = None\n",
    "    tensor_parallel = 1\n",
    "else:\n",
    "    enable_lora = True; lora_req = LoRARequest(\"lora_adapter\", 1, ADAPTER_PATH) if ADAPTER_PATH else None;\n",
    "    tensor_parallel = torch.cuda.device_count()\n",
    "\n",
    "model = LLM(\n",
    "    model=MODEL_PATH,\n",
    "    quantization=\"bitsandbytes\",\n",
    "    max_model_len=4096,\n",
    "    tensor_parallel_size=tensor_parallel,\n",
    "    enable_prefix_caching=True,\n",
    "    gpu_memory_utilization=0.5,\n",
    "    enforce_eager=True,\n",
    "    enable_lora=enable_lora,\n",
    "    max_lora_rank=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703e180e-6e28-45ce-9f1f-ed31c28b953d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc974f9040a4e95b308c3c5bed4632a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/2785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m WARNING 11-16 04:18:58 [cudagraph_dispatcher.py:101] cudagraph dispatching keys are not initialized. No cudagraph will be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93465763250486fad2c5228cf054ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/2785 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m [rank0]:W1116 04:20:48.646000 2760734 /lustrefs/disk/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:964] [0/8] torch._dynamo hit config.recompile_limit (8)\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m [rank0]:W1116 04:20:48.646000 2760734 /lustrefs/disk/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:964] [0/8]    function: 'forward_static' (/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/vllm/model_executor/layers/layernorm.py:221)\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m [rank0]:W1116 04:20:48.646000 2760734 /lustrefs/disk/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:964] [0/8]    last reason: 0/7: expected type of 'residual' to be a tensor type, ' but found <class 'NoneType'>\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m [rank0]:W1116 04:20:48.646000 2760734 /lustrefs/disk/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:964] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "\u001b[1;36m(EngineCore_0 pid=2760734)\u001b[0;0m [rank0]:W1116 04:20:48.646000 2760734 /lustrefs/disk/home/psoratya/.conda/envs/unsloth_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:964] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"thai_translation\": \"‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤, ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏ö‡∏£‡∏°, ‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à, ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\"}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_params = SamplingParams(\n",
    "    temperature=0.0, top_p=1, top_k=-1,\n",
    "    max_tokens=4096,\n",
    "    skip_special_tokens=True,\n",
    "    repetition_penalty=1.15,\n",
    "    frequency_penalty=0.2,\n",
    ")\n",
    "\n",
    "results = model.generate(test_set, decoding_params, lora_request=lora_req)\n",
    "response = [r.outputs[0].text for r in results]\n",
    "response[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0192a-c099-4668-a1d9-e890d6ae09e4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155343bf-5dd4-45cf-ba4c-b25f51b577bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null rows:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ENG</th>\n",
       "      <th>THA</th>\n",
       "      <th>WIPO</th>\n",
       "      <th>PRED</th>\n",
       "      <th>PRED_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Educational services, namely, conducting semin...</td>\n",
       "      <td>‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "      <td>{\"thai_translation\": \"‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡πÑ‡∏î‡πâ‡πÅ...</td>\n",
       "      <td>‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏Å‡∏≤‡∏£‡∏õ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>training of drivers, road service employees, o...</td>\n",
       "      <td>‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "      <td>{\"thai_translation\": \"‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ, ‡∏û‡∏ô‡∏±‡∏Å‡∏á...</td>\n",
       "      <td>‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>providing online publications in the nature of...</td>\n",
       "      <td>‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ‡∏õ‡∏£‡∏∞...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "      <td>{\"thai_translation\": \"‡πÉ‡∏´‡πâ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå...</td>\n",
       "      <td>‡πÉ‡∏´‡πâ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>information with respect to leisure activities...</td>\n",
       "      <td>‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "      <td>{\"thai_translation\": \"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±...</td>\n",
       "      <td>‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>planning, arranging and operating of movies, s...</td>\n",
       "      <td>‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞‡∏Ñ...</td>\n",
       "      <td>Education; providing of training; entertainmen...</td>\n",
       "      <td>{\"thai_translation\": \"‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô...</td>\n",
       "      <td>‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ ‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME                                                ENG  \\\n",
       "0    41  Educational services, namely, conducting semin...   \n",
       "1    41  training of drivers, road service employees, o...   \n",
       "2    41  providing online publications in the nature of...   \n",
       "3    41  information with respect to leisure activities...   \n",
       "4    41  planning, arranging and operating of movies, s...   \n",
       "\n",
       "                                                 THA  \\\n",
       "0  ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ...   \n",
       "1  ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ...   \n",
       "2  ‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ‡∏õ‡∏£‡∏∞...   \n",
       "3  ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å...   \n",
       "4  ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞‡∏Ñ...   \n",
       "\n",
       "                                                WIPO  \\\n",
       "0  Education; providing of training; entertainmen...   \n",
       "1  Education; providing of training; entertainmen...   \n",
       "2  Education; providing of training; entertainmen...   \n",
       "3  Education; providing of training; entertainmen...   \n",
       "4  Education; providing of training; entertainmen...   \n",
       "\n",
       "                                                PRED  \\\n",
       "0  {\"thai_translation\": \"‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡πÑ‡∏î‡πâ‡πÅ...   \n",
       "1  {\"thai_translation\": \"‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ, ‡∏û‡∏ô‡∏±‡∏Å‡∏á...   \n",
       "2  {\"thai_translation\": \"‡πÉ‡∏´‡πâ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå...   \n",
       "3  {\"thai_translation\": \"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±...   \n",
       "4  {\"thai_translation\": \"‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô...   \n",
       "\n",
       "                                        PRED_cleaned  \n",
       "0  ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤ ‡∏Å‡∏≤‡∏£‡∏õ...  \n",
       "1  ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô ‡∏ú‡∏π‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±...  \n",
       "2  ‡πÉ‡∏´‡πâ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏à‡∏î‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß ...  \n",
       "3         ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤  \n",
       "4  ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ ‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á ‡∏•‡∏∞...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_thai(text):\n",
    "    pattern = r'[\\u0e00-\\u0e7f\\s,.?!]+'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return \"\".join(matches).strip().replace(\"\\n\", \"\")\n",
    "\n",
    "def extract_json(text):\n",
    "    text = text[text.rfind(\"{\"):]\n",
    "    pattern = r'''{\\s*[\\'\\\"]thai_translation[\\'\\\"]:\\s*[\\'\\\"].*?[\\'\\\"]\\s*}'''\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    if matches:\n",
    "        try:\n",
    "            loaded = json.loads(matches[0])\n",
    "            return loaded['thai_translation'].replace(\",\", \"\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            return filter_thai(text)\n",
    "    else:\n",
    "        return filter_thai(text)\n",
    "\n",
    "\n",
    "test_df['PRED'] = response\n",
    "test_df['PRED_cleaned'] = test_df['PRED'].apply(extract_json)\n",
    "print(\"Null rows: \", test_df['PRED_cleaned'].isnull().sum())\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa74ba17-7dae-403d-a0fd-f32adf14907b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2785/2785 [00:18<00:00, 148.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CER: 0.2904\n",
      "Average BLEU: 0.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cer_result, bleu = [], []\n",
    "chencherry = SmoothingFunction().method1\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    sol = row[\"THA\"]\n",
    "    pred = \"\" if pd.isna(row[\"PRED_cleaned\"]) else row[\"PRED_cleaned\"]\n",
    "\n",
    "    # bleu score\n",
    "    ref = word_tokenize(sol, engine='attacut')\n",
    "    hyp = word_tokenize(pred, engine='attacut')\n",
    "\n",
    "    ref = [word for word in ref if not word.isspace()]\n",
    "    hyp = [word for word in hyp if not word.isspace()]\n",
    "    \n",
    "    cer_result.append(cer(sol, pred))\n",
    "    bleu.append(sentence_bleu([ref], hyp, smoothing_function=chencherry))\n",
    "\n",
    "test_df[\"BLEU\"] = bleu\n",
    "print(f\"Average CER:\", np.mean(cer_result).round(4))\n",
    "print(f\"Average BLEU:\", np.mean(bleu).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4e6709-b11e-419b-a075-ad124da41c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save at /project/lt200304-dipmt/paweekorn/data/infer-result/en2th/gemma3-4b-it_base.csv already!\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = MODEL_PATH.split('/')[-1] if \"checkpoint\" not in MODEL_PATH else MODEL_PATH.split('/')[-2]\n",
    "fname = f\"{MODEL_ID}_base\"\n",
    "save_path = f\"{ROOT_DIR}/data/infer-result/en2th/{fname}.csv\"\n",
    "test_df[['PRED', 'PRED_cleaned']].to_csv(save_path, index=False)\n",
    "print(f\"Save at {save_path} already!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813414c-00bc-4d7c-839e-4b60413aa7dd",
   "metadata": {},
   "source": [
    "## Check memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e019de-ad54-4075-a777-e660c53fa765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 1.6%\n",
      "Total Memory: 502.45 GB\n",
      "Available Memory: 480.91 GB\n",
      "Used Memory: 14.16 GB\n",
      "Memory Usage Percentage: 4.3%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get CPU usage percentage\n",
    "cpu_percent = psutil.cpu_percent(interval=1)\n",
    "print(f\"CPU Usage: {cpu_percent}%\")\n",
    "\n",
    "# Get detailed virtual memory information\n",
    "virtual_memory = psutil.virtual_memory()\n",
    "\n",
    "# Print various memory statistics\n",
    "print(f\"Total Memory: {virtual_memory.total / (1024**3):.2f} GB\")  # Convert bytes to GB\n",
    "print(f\"Available Memory: {virtual_memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"Used Memory: {virtual_memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"Memory Usage Percentage: {virtual_memory.percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e375c2-8dfe-48cd-a389-b7cf3ec6789d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 16 04:21:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:03:00.0 Off |                    0 |\n",
      "| N/A   39C    P0             62W /  400W |   22549MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             49W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2752506      C   .../.conda/envs/unsloth_env/bin/python       2446MiB |\n",
      "|    0   N/A  N/A   2760734      C   VLLM::EngineCore                            20086MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe159481-8d3a-453a-bcd5-59c2618bdca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
